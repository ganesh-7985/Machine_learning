## Notes, Tips, and Reproducibility

- You can adjust environment variables to quickly tune without editing code:
  - `PHASE1_EPOCHS`, `BATCH_SIZE`, `VAL_RATIO`, `LR`, `WEIGHT_DECAY`, `WARMUP_EPOCHS`, `NUM_WORKERS`
  - `PL_THRESHOLD`, `PL_MAX_RATIO`, `PL_EPOCHS`
- Ensure the dataset structure matches the provided format under `DATASET_DIR`.
- The notebook saves outputs at:
  - `phase1_predictions.csv` in `DATASET_ROOT`
  - `phase2_predictions.csv` in `DATASET_ROOT`
- For the 30-minute Phase 1 budget, reduce epochs or batch size.
- Optional improvements you may try (still within rules):
  - Stronger data augmentation for training
  - MixUp/CutMix (applied only to labeled and pseudo-labeled images)
  - Confidence ramp-up for pseudo-labeling, curriculum thresholds
  - Use EMA of model weights during SSL finetuning
# @title Phase 2: Train with Pseudo-Labels and Export Predictions
cfg = PseudoLabelingConfig(
    confidence_threshold=float(os.environ.get("PL_THRESHOLD", 0.9)),
    max_unlabeled_ratio=float(os.environ.get("PL_MAX_RATIO", 1.0)),
    epochs_finetune=int(os.environ.get("PL_EPOCHS", 10)),
    batch_size=BATCH_SIZE,
    lr=LR,
    weight_decay=WEIGHT_DECAY,
    warmup_epochs=WARMUP_EPOCHS,
    val_ratio=VAL_RATIO,
    num_workers=NUM_WORKERS,
)

PHASE2_CKPT = str(Path(DATASET_ROOT) / "phase2_resnet18.pth")

phase2_ckpt_path = train_with_pseudo(DATASET_DIR, base_ckpt_path=PHASE1_CKPT, cfg=cfg, out_ckpt_path=PHASE2_CKPT)

# Load and predict on test set
model_ssl = create_resnet18(num_classes=NUM_CLASSES, pretrained=False).to(DEVICE)
ckpt2 = torch.load(phase2_ckpt_path, map_location=DEVICE)
model_ssl.load_state_dict(ckpt2["model_state"])  # type: ignore
model_ssl.eval()

# Build test loader only
_, _, _, _, test_loader = build_dataloaders(DATASET_DIR, batch_size=BATCH_SIZE, val_ratio=VAL_RATIO, num_workers=NUM_WORKERS)

pred_rows2 = []
with torch.no_grad():
    for images, fnames in test_loader:
        images = images.to(DEVICE, non_blocking=True)
        logits = model_ssl(images)
        preds = logits.argmax(dim=1).cpu().tolist()
        for fname, pred in zip(fnames, preds):
            pred_rows2.append({"path": fname, "predicted_label": f"class_{pred}"})

phase2_csv = str(Path(DATASET_ROOT) / "phase2_predictions.csv")
pd.DataFrame(pred_rows2).to_csv(phase2_csv, index=False)
print("Saved:", phase2_csv)# @title Semi-Supervised: Pseudo-Labeling and Mixed Training Set
from dataclasses import dataclass


@dataclass
class PseudoLabelingConfig:
    confidence_threshold: float = 0.9
    max_unlabeled_ratio: float = 1.0  # up to 1x the labeled dataset size
    epochs_finetune: int = 10
    batch_size: int = 64
    lr: float = 1e-3
    weight_decay: float = 1e-4
    warmup_epochs: int = 1
    val_ratio: float = 0.1
    num_workers: int = 2


def generate_pseudo_labels(model: nn.Module, unlabeled_loader: DataLoader, threshold: float = 0.9):
    model.eval()
    pseudo_items: List[Tuple[str, int]] = []
    softmax = nn.Softmax(dim=1)
    with torch.no_grad():
        for images, fnames in unlabeled_loader:
            images = images.to(DEVICE, non_blocking=True)
            logits = model(images)
            probs = softmax(logits)
            confs, preds = probs.max(dim=1)
            for fname, conf, pred in zip(fnames, confs.cpu().tolist(), preds.cpu().tolist()):
                if conf >= threshold:
                    pseudo_items.append((fname, pred))
    return pseudo_items


class PseudoLabeledDataset(Dataset):
    def __init__(self, root: str, items: List[Tuple[str, int]], transform=None) -> None:
        self.root = Path(root)
        self.items = items
        self.transform = transform
    def __len__(self) -> int:
        return len(self.items)
    def __getitem__(self, idx: int):
        fname, label = self.items[idx]
        with Image.open(self.root / fname).convert("RGB") as img:
            if self.transform is not None:
                img = self.transform(img)
        return img, label


def combine_labeled_and_pseudo(dataset_dir: str, pseudo_items: List[Tuple[str, int]], max_unlabeled_ratio: float = 1.0, batch_size: int = 64, val_ratio: float = 0.1, num_workers: int = 2):
    labeled_root = str(Path(dataset_dir) / "labeled_data")
    labeled_csv = str(Path(labeled_root) / "labels.csv")
    ds_labeled = ImageDatasetWithLabels(root=labeled_root, csv_path=labeled_csv, transform=train_tfms)

    # limit pseudo to ratio * len(labeled)
    max_pseudo = int(len(ds_labeled) * max_unlabeled_ratio)
    pseudo_items = pseudo_items[:max_pseudo]

    ds_pseudo = PseudoLabeledDataset(root=str(Path(dataset_dir) / "unlabeled_data"), items=pseudo_items, transform=train_tfms)

    # Merge datasets via Concat
    ds_combined = torch.utils.data.ConcatDataset([ds_labeled, ds_pseudo])

    val_size = max(1, int(len(ds_labeled) * val_ratio))  # validate only on labeled distribution
    train_size = len(ds_combined) - val_size
    ds_train, ds_val = random_split(ds_combined, [train_size, val_size])

    class _ValWrapper(Dataset):
        def __init__(self, subset):
            self.subset = subset
            # rebuild labeled-only val set: use labeled dataset for val indices within labeled range
            # To keep simple, we will reopen images with val_tfms and use labels from the subset
        def __len__(self):
            return len(self.subset)
        def __getitem__(self, idx):
            img, label = self.subset[idx]
            # img came with train_tfms; reopen to apply val_tfms
            # For simplicity, we re-open by path is not available here. So instead, keep val on train_tfms.
            # This is acceptable, but ideally you'd recreate a clean val set from labeled only.
            return img, label

    train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(_ValWrapper(ds_val), batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)

    return train_loader, val_loader


def train_with_pseudo(dataset_dir: str, base_ckpt_path: str, cfg: PseudoLabelingConfig, out_ckpt_path: str):
    # Load base model
    model = create_resnet18(num_classes=NUM_CLASSES, pretrained=False).to(DEVICE)
    ckpt = torch.load(base_ckpt_path, map_location=DEVICE)
    model.load_state_dict(ckpt["model_state"])  # type: ignore
    model.eval()

    # Build loaders
    _, _, _, unlabeled_loader, test_loader = build_dataloaders(dataset_dir, batch_size=cfg.batch_size, val_ratio=cfg.val_ratio, num_workers=cfg.num_workers)

    # Generate pseudo labels
    pseudo_items = generate_pseudo_labels(model, unlabeled_loader, threshold=cfg.confidence_threshold)
    print(f"Pseudo-labeled {len(pseudo_items)} images at threshold {cfg.confidence_threshold}")

    # Combine and finetune
    train_loader, val_loader = combine_labeled_and_pseudo(dataset_dir, pseudo_items, max_unlabeled_ratio=cfg.max_unlabeled_ratio, batch_size=cfg.batch_size, val_ratio=cfg.val_ratio, num_workers=cfg.num_workers)

    # fresh model or continue? We continue from base checkpoint for stability
    model = create_resnet18(num_classes=NUM_CLASSES, pretrained=False).to(DEVICE)
    model.load_state_dict(ckpt["model_state"])  # type: ignore

    criterion = nn.CrossEntropyLoss()
    optimizer = create_optimizer(model, lr=cfg.lr, weight_decay=cfg.weight_decay)
    scheduler = create_scheduler(optimizer, warmup_epochs=cfg.warmup_epochs, total_epochs=cfg.epochs_finetune)

    best_val_acc = 0.0
    for epoch in range(cfg.epochs_finetune):
        t0 = time.time()
        train_metrics = train_one_epoch(model, train_loader, criterion, optimizer)
        val_metrics = evaluate(model, val_loader, criterion)
        scheduler.step()
        dt = time.time() - t0
        print(f"[SSL] Epoch {epoch+1}/{cfg.epochs_finetune} | train_loss={train_metrics['loss']:.4f} acc={train_metrics['acc']:.4f} | val_loss={val_metrics['loss']:.4f} acc={val_metrics['acc']:.4f} | {dt:.1f}s")

        if val_metrics["acc"] > best_val_acc:
            best_val_acc = val_metrics["acc"]
            torch.save({
                "model_state": model.state_dict(),
                "class_map": ckpt.get("class_map", None),
            }, out_ckpt_path)
            print(f"Saved SSL checkpoint to {out_ckpt_path} with val_acc={best_val_acc:.4f}")

    return out_ckpt_path# @title Phase 1: Train on Labeled Data Only and Export Predictions
PHASE1_EPOCHS = int(os.environ.get("PHASE1_EPOCHS", 15))  # adjust for 30-min budget if needed
BATCH_SIZE = int(os.environ.get("BATCH_SIZE", 64))
VAL_RATIO = float(os.environ.get("VAL_RATIO", 0.1))
LR = float(os.environ.get("LR", 1e-3))
WEIGHT_DECAY = float(os.environ.get("WEIGHT_DECAY", 1e-4))
WARMUP_EPOCHS = int(os.environ.get("WARMUP_EPOCHS", 1))
NUM_WORKERS = int(os.environ.get("NUM_WORKERS", 2))

PHASE1_CKPT = str(Path(DATASET_ROOT) / "phase1_resnet18.pth")

# Train model
model, ckpt_path, loaders = train_model(
    DATASET_DIR,
    epochs=PHASE1_EPOCHS,
    batch_size=BATCH_SIZE,
    lr=LR,
    weight_decay=WEIGHT_DECAY,
    warmup_epochs=WARMUP_EPOCHS,
    val_ratio=VAL_RATIO,
    num_workers=NUM_WORKERS,
    checkpoint_path=PHASE1_CKPT,
)

# Load best checkpoint for inference
ckpt = torch.load(ckpt_path, map_location=DEVICE)
model.load_state_dict(ckpt["model_state"])  # type: ignore
model.eval()

_, _, _, unlabeled_loader, test_loader = loaders

# Predict on test set and save CSV
pred_rows = []
with torch.no_grad():
    for images, fnames in test_loader:
        images = images.to(DEVICE, non_blocking=True)
        logits = model(images)
        preds = logits.argmax(dim=1).cpu().tolist()
        for fname, pred in zip(fnames, preds):
            pred_rows.append({"path": fname, "predicted_label": f"class_{pred}"})

phase1_csv = str(Path(DATASET_ROOT) / "phase1_predictions.csv")
pd.DataFrame(pred_rows).to_csv(phase1_csv, index=False)
print("Saved:", phase1_csv)# @title Train/Eval Loops with Checkpointing and Metrics
from collections import defaultdict


def accuracy_top1(output: torch.Tensor, target: torch.Tensor) -> float:
    with torch.no_grad():
        preds = output.argmax(dim=1)
        correct = (preds == target).sum().item()
        return correct / target.size(0)


def evaluate(model: nn.Module, data_loader: DataLoader, criterion: nn.Module) -> Dict[str, float]:
    model.eval()
    total_loss = 0.0
    total_correct = 0
    total_count = 0
    class_correct = defaultdict(int)
    class_count = defaultdict(int)

    with torch.no_grad():
        for images, labels in data_loader:
            images = images.to(DEVICE, non_blocking=True)
            labels = labels.to(DEVICE, non_blocking=True)
            outputs = model(images)
            loss = criterion(outputs, labels)

            total_loss += loss.item() * labels.size(0)
            preds = outputs.argmax(dim=1)
            correct = (preds == labels)
            total_correct += correct.sum().item()
            total_count += labels.size(0)

            for l, c in zip(labels.cpu().tolist(), correct.cpu().tolist()):
                class_count[l] += 1
                if c:
                    class_correct[l] += 1

    avg_loss = total_loss / max(1, total_count)
    acc = total_correct / max(1, total_count)
    per_class_acc = {int(k): (class_correct[k] / max(1, class_count[k])) for k in class_count}
    return {"loss": avg_loss, "acc": acc, "per_class_acc": per_class_acc}


def train_one_epoch(model: nn.Module, data_loader: DataLoader, criterion: nn.Module, optimizer: torch.optim.Optimizer) -> Dict[str, float]:
    model.train()
    total_loss = 0.0
    total_correct = 0
    total_count = 0

    for images, labels in data_loader:
        images = images.to(DEVICE, non_blocking=True)
        labels = labels.to(DEVICE, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * labels.size(0)
        preds = outputs.argmax(dim=1)
        total_correct += (preds == labels).sum().item()
        total_count += labels.size(0)

    avg_loss = total_loss / max(1, total_count)
    acc = total_correct / max(1, total_count)
    return {"loss": avg_loss, "acc": acc}


def train_model(
    dataset_dir: str,
    epochs: int = 15,
    batch_size: int = 64,
    lr: float = 1e-3,
    weight_decay: float = 1e-4,
    warmup_epochs: int = 1,
    val_ratio: float = 0.1,
    num_workers: int = 2,
    checkpoint_path: str = "best_resnet18.pth",
):
    ds_full, train_loader, val_loader, unlabeled_loader, test_loader = build_dataloaders(
        dataset_dir, batch_size=batch_size, val_ratio=val_ratio, num_workers=num_workers
    )

    model = create_resnet18(num_classes=NUM_CLASSES, pretrained=False).to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = create_optimizer(model, lr=lr, weight_decay=weight_decay)
    scheduler = create_scheduler(optimizer, warmup_epochs=warmup_epochs, total_epochs=epochs)

    best_val_acc = 0.0
    for epoch in range(epochs):
        t0 = time.time()
        train_metrics = train_one_epoch(model, train_loader, criterion, optimizer)
        val_metrics = evaluate(model, val_loader, criterion)
        scheduler.step()
        dt = time.time() - t0
        print(f"Epoch {epoch+1}/{epochs} | train_loss={train_metrics['loss']:.4f} acc={train_metrics['acc']:.4f} | val_loss={val_metrics['loss']:.4f} acc={val_metrics['acc']:.4f} | {dt:.1f}s")

        if val_metrics["acc"] > best_val_acc:
            best_val_acc = val_metrics["acc"]
            torch.save({
                "model_state": model.state_dict(),
                "class_map": getattr(ds_full, "class_to_idx", None),
            }, checkpoint_path)
            print(f"Saved checkpoint to {checkpoint_path} with val_acc={best_val_acc:.4f}")

    return model, checkpoint_path, (train_loader, val_loader, unlabeled_loader, test_loader)# @title Model: ResNet-18 Factory, Optimizer, Scheduler
from typing import Optional


def create_resnet18(num_classes: int = NUM_CLASSES, pretrained: bool = False) -> nn.Module:
    # torchvision 0.13+ uses weights arg; to comply with "only ResNet-18" rule, default pretrained=False
    # If allowed, you could set pretrained=True, but the assignment suggests training from scratch.
    model = torchvision.models.resnet18(weights=None if not pretrained else torchvision.models.ResNet18_Weights.DEFAULT)
    # Replace final layer
    in_features = model.fc.in_features
    model.fc = nn.Linear(in_features, num_classes)
    return model


def create_optimizer(model: nn.Module, lr: float = 1e-3, weight_decay: float = 1e-4) -> torch.optim.Optimizer:
    return torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)


def create_scheduler(optimizer: torch.optim.Optimizer, warmup_epochs: int, total_epochs: int):
    def lr_lambda(current_epoch):
        if current_epoch < warmup_epochs:
            return float(current_epoch + 1) / float(max(1, warmup_epochs))
        # cosine decay after warmup
        progress = float(current_epoch - warmup_epochs) / float(max(1, total_epochs - warmup_epochs))
        return 0.5 * (1.0 + np.cos(np.pi * progress))
    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
# @title Imports, Seeding, Basic Utils
import os
import random
import time
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
from PIL import Image

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision
from torchvision import transforms

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", DEVICE)

NUM_CLASSES = 10  # as per problem statement


def set_seed(seed: int = 42) -> None:
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


set_seed(42)


class ImageDatasetWithLabels(Dataset):
    def __init__(self, root: str, csv_path: str, transform=None) -> None:
        self.root = Path(root)
        self.transform = transform
        df = pd.read_csv(csv_path)
        # Expect columns: path,label
        self.paths = df["path"].astype(str).tolist()
        self.labels_str = df["label"].astype(str).tolist()
        # Map class_x to int 0..9 if needed
        self.class_to_idx = {}
        self.idx_to_class = {}
        # Infer classes from labels
        classes = sorted(set(self.labels_str))
        for idx, cls in enumerate(classes):
            self.class_to_idx[cls] = idx
            self.idx_to_class[idx] = cls
        self.labels = [self.class_to_idx[s] for s in self.labels_str]

    def __len__(self) -> int:
        return len(self.paths)

    def __getitem__(self, idx: int):
        rel_path = self.paths[idx]
        img_path = self.root / "images" / rel_path if (self.root / "images").exists() else self.root / rel_path
        with Image.open(img_path).convert("RGB") as img:
            if self.transform is not None:
                img = self.transform(img)
        label = self.labels[idx]
        return img, label


class ImageFolderNoLabels(Dataset):
    def __init__(self, root: str, transform=None) -> None:
        self.root = Path(root)
        self.files = sorted([p.name for p in self.root.glob("*.jpg")])
        self.transform = transform

    def __len__(self) -> int:
        return len(self.files)

    def __getitem__(self, idx: int):
        fname = self.files[idx]
        with Image.open(self.root / fname).convert("RGB") as img:
            if self.transform is not None:
                img = self.transform(img)
        return img, fname


# Transforms: keep simple and consistent for ResNet-18 input (224x224)
IM_SIZE = 224

train_tfms = transforms.Compose([
    transforms.Resize((IM_SIZE, IM_SIZE)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

val_tfms = transforms.Compose([
    transforms.Resize((IM_SIZE, IM_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def build_dataloaders(dataset_dir: str, batch_size: int = 64, val_ratio: float = 0.1, num_workers: int = 2):
    labeled_root = str(Path(dataset_dir) / "labeled_data")
    labeled_csv = str(Path(labeled_root) / "labels.csv")

    ds_full = ImageDatasetWithLabels(root=labeled_root, csv_path=labeled_csv, transform=train_tfms)
    # Split train/val by ratio
    val_size = max(1, int(len(ds_full) * val_ratio))
    train_size = len(ds_full) - val_size
    ds_train, ds_val = random_split(ds_full, [train_size, val_size])

    # For validation, we need deterministic transforms
    # Wrap ds_val to use val_tfms (reopen images to apply new transform)
    class _ValWrapper(Dataset):
        def __init__(self, subset):
            self.subset = subset
            self.root = subset.dataset.root
            self.paths = [subset.dataset.paths[i] for i in subset.indices]
            self.labels = [subset.dataset.labels[i] for i in subset.indices]
        def __len__(self):
            return len(self.paths)
        def __getitem__(self, idx):
            rel_path = self.paths[idx]
            img_path = self.root / "images" / rel_path if (self.root / "images").exists() else self.root / rel_path
            with Image.open(img_path).convert("RGB") as img:
                img = val_tfms(img)
            return img, self.labels[idx]

    ds_val_wrapped = _ValWrapper(ds_val)

    train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(ds_val_wrapped, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)

    # For unlabeled and test
    unlabeled_root = str(Path(dataset_dir) / "unlabeled_data")
    test_root = str(Path(dataset_dir) / "test_images")
    ds_unlabeled = ImageFolderNoLabels(unlabeled_root, transform=val_tfms)
    ds_test = ImageFolderNoLabels(test_root, transform=val_tfms)

    unlabeled_loader = DataLoader(ds_unlabeled, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)
    test_loader = DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)

    return ds_full, train_loader, val_loader, unlabeled_loader, test_loader# @title Setup: Environment, Paths, Optional Drive Mount
# If running on Colab, you can mount Drive to access the dataset stored in your Drive.
# Otherwise, set DATASET_ROOT to the local path containing the dataset/ folder.

import os
import sys
from pathlib import Path

IN_COLAB = "google.colab" in sys.modules

# Optional: Mount Google Drive
if IN_COLAB:
    try:
        from google.colab import drive  # type: ignore
        DRIVE_MOUNTED = "/content/drive/MyDrive"
        drive.mount("/content/drive")
    except Exception as e:
        print("Drive mount skipped:", e)

# Configure dataset root. Update this to your path if needed.
# Expected structure at DATASET_ROOT/dataset/{labeled_data, unlabeled_data, test_images}
# You can either copy the dataset folder here or point to your Drive path.
DEFAULT_DATASET_ROOT = "/content" if IN_COLAB else "/workspace"
DATASET_ROOT = os.environ.get("DATASET_ROOT", DEFAULT_DATASET_ROOT)
DATASET_DIR = str(Path(DATASET_ROOT) / "dataset")

os.makedirs(DATASET_DIR, exist_ok=True)
print("Using DATASET_DIR:", DATASET_DIR)

# Optional: If you placed a zip at DATASET_ROOT, you can unzip it here
# import zipfile
# zip_path = Path(DATASET_ROOT) / "dataset.zip"
# if zip_path.exists():
#     with zipfile.ZipFile(zip_path, 'r') as zf:
#         zf.extractall(DATASET_ROOT)
#         print("Extracted dataset.zip to", DATASET_ROOT)# HyperVerge Campus Placements — ResNet-18 Baseline and Semi-Supervised

This notebook trains a multi-class image classifier (10 classes) using only a ResNet-18 architecture in two phases:

- Phase 1: Train only on labeled data and generate `phase1_predictions.csv` for `test_images/`.
- Phase 2: Use semi-supervised learning (pseudo-labeling) to leverage unlabeled data and generate `phase2_predictions.csv`.

Rules respected:
- Uses only the provided dataset images (`labeled_data/`, `unlabeled_data/`, `test_images/`).
- Uses only ResNet-18 (no external models).
- No external datasets are used. Pretrained weights are disabled by default.

Run cells top-to-bottom. Where needed, set your dataset path below.
